# -*- coding: utf-8 -*-
"""1234.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bh7y0BfGTV_WtBOfw2DMRLxR5xsJdwy5
"""

!pip install ultralytics

import os
import yaml
import cv2
import torch
import numpy as np
from pathlib import Path
from ultralytics import YOLO

!pip install ultralytics

from ultralytics import YOLO
import cv2
import torch
import numpy as np
import os
from google.colab.patches import cv2_imshow
import pandas as pd
import random
import matplotlib.pyplot as plt

"""The error `ModuleNotFoundError: No module named 'ultralytics'` means that the Python environment does not have the `ultralytics` library installed. The code above uses `!pip install ultralytics` to install the library. After running this cell, you should be able to import `YOLO` without errors."""

dataset_path = Path("/content/drive/MyDrive/archive (3)/trafic_data")
train_images_path = dataset_path / "/content/drive/MyDrive/archive (3)/trafic_data/train/images"
train_labels_path = dataset_path / "/content/drive/MyDrive/archive (3)/trafic_data/train/labels"
valid_images_path = dataset_path / "/content/drive/MyDrive/archive (3)/trafic_data/valid/images"
valid_labels_path = dataset_path / "/content/drive/MyDrive/archive (3)/trafic_data/valid/labels"
yaml_path = dataset_path / "/content/drive/MyDrive/archive (3)/trafic_data/valid/labels.cache"

train_images_path = dataset_path / "train/images"
train_labels_path = dataset_path / "train/labels"
valid_images_path = dataset_path / "valid/images"
valid_labels_path = dataset_path / "valid/labels"
yaml_path = dataset_path / "data.yaml"  # your YAML file

# Save this as data_1.yaml in your working directory

data_yaml = """
train: /content/drive/MyDrive/archive (3)/trafic_data/train
val: /content/drive/MyDrive/archive (3)/trafic_data/valid

nc: 3
names: ['car', 'truck', 'bus']
"""

with open("data_1.yaml", "w") as f:
    f.write(data_yaml)

imgs_dir= "/content/drive/MyDrive/archive (3)/trafic_data/train/images"

for file in os.listdir(imgs_dir)[:9]:
    img= cv2.imread(os.path.join(imgs_dir, file))
    cv2_imshow(img)

def check_dataset(images_path, labels_path):
    image_files = list(images_path.glob("*.jpg")) + list(images_path.glob("*.png"))
    label_files = list(labels_path.glob("*.txt"))
    if len(image_files) == 0 or len(label_files) == 0:
        raise ValueError("Dataset images or labels missing")
    print(f"Found {len(image_files)} images and {len(label_files)} labels.")

check_dataset(train_images_path, train_labels_path)
check_dataset(valid_images_path, valid_labels_path)

yaml_file_path = dataset_path / "data.yaml"
if not yaml_file_path.exists():
    data_yaml = {
        'train': str(train_images_path),
        'val': str(valid_images_path),
        'nc': 5,  # number of classes, change according to your dataset
        'names': ['car', 'bus', 'truck', 'motorbike', 'traffic_light']  # modify for your dataset
    }
    with open(yaml_file_path, 'w') as f:
        yaml.dump(data_yaml, f)
    print(f"Created YAML file at {yaml_file_path}")

import glob

nc = 5  # number of classes

def fix_labels(label_dir, nc):
    txt_files = glob.glob(f"{label_dir}/*.txt")
    for file in txt_files:
        lines = open(file).readlines()
        new_lines = []
        for line in lines:
            cls_id, *rest = line.strip().split()
            cls_id = int(cls_id)
            if cls_id < nc:  # only keep valid class IDs
                new_lines.append(line)
        with open(file, 'w') as f:
            f.writelines(new_lines)

# Apply to both train and valid labels
fix_labels(str(train_labels_path), nc)
fix_labels(str(valid_labels_path), nc)

model = YOLO("yolov8n.pt")  # using nano model for faster training; change to yolov8s.pt for better accuracy

# Train model
def train_model(model, data_yaml):
    results = model.train(
        data=str(data_yaml),
        epochs=50,
        imgsz=640,
        batch=16,
        device='0' if torch.cuda.is_available() else 'cpu',
        lr0=0.001,
        optimizer='SGD',
        project='traffic_management',
        name='yolo_traffic',
        exist_ok=True
    )
    return results

train_results = train_model(model, yaml_path)

def evaluate_model(model, valid_images_path):
    metrics = model.val(data=str(yaml_path), imgsz=640)
    print("Validation metrics:", metrics)

evaluate_model(model, valid_images_path)

def run_inference(model, image_path, save_path="inference_results"):
    os.makedirs(save_path, exist_ok=True)
    img_files = list(Path(image_path).glob("*.jpg")) + list(Path(image_path).glob("*.png"))

    for img_file in img_files:
        results = model.predict(str(img_file), imgsz=640, conf=0.5)
        # Draw boxes on the image
        result_img = results[0].plot()
        save_file = Path(save_path) / img_file.name
        cv2.imwrite(str(save_file), cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR))
        print(f"Saved inference result at {save_file}")

run_inference(model, valid_images_path)

def traffic_management(image_path):
    results = model.predict(image_path, imgsz=640, conf=0.5)
    detections = results[0].boxes.xyxy
    labels = results[0].boxes.cls

    traffic_status = "Clear"
    for cls_id in labels:
        if cls_id in [0, 1, 2]:  # car, bus, truck
            traffic_status = "Heavy Traffic"
            break
    print(f"Traffic Status: {traffic_status}")
    return traffic_status

from google.colab import files
uploaded = files.upload()  # Upload an image manually

# Suppose you uploaded 'test_image.jpg'
test_image_path = "/content/drive/MyDrive/archive (3)/trafic_data/train/images/04_jpg.rf.c0b83432c4d09c7cbeaac18e14c4a54a.jpg"
traffic_status = traffic_management(test_image_path)
print("Traffic status:", traffic_status)

import os

valid_images = os.listdir(valid_images_path)
print("Available validation images:", valid_images[:10])  # show first 10 images

# Pick a real image from your dataset
example_image = valid_images_path / "Pias--359-_PNG.rf.43bcf36efe5cf8c37552d2c45fffea60.jpg"

traffic_status = traffic_management(str(example_image))
print("Traffic status:", traffic_status)

from google.colab import files
uploaded = files.upload()  # Upload an image manually

# Suppose you uploaded 'test_image.jpg'
test_image_path = "/content/drive/MyDrive/archive (3)/trafic_data/train/images/03_jpg.rf.4532f2db68433995da09f54e215160f3.png"
traffic_status = traffic_management(test_image_path)
print("Traffic status:", traffic_status)

!pip install ultralytics --upgrade

!yolo task=detect mode=train model=yolov8n.pt data=data_1.yaml epochs=50 batch=16 imgsz=640

import os

label_dir = "/content/drive/MyDrive/archive (3)/trafic_data/train/labels"

for file in os.listdir(label_dir):
    path = os.path.join(label_dir, file)
    with open(path, 'r') as f:
        lines = f.readlines()
        for i, line in enumerate(lines):
            parts = line.strip().split()
            if len(parts) != 5:
                print(f"Invalid format: {path} line {i+1}")
                continue
            cls, x, y, w, h = parts
            x, y, w, h = map(float, [x, y, w, h])
            if not (0 <= x <= 1 and 0 <= y <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                print(f"Out of bounds: {path} line {i+1}")
            if x - w/2 < 0 or x + w/2 > 1 or y - h/2 < 0 or y + h/2 > 1:
                print(f"Box outside image: {path} line {i+1}")

train_out_dir= "/content/drive/MyDrive/archive (3)/trafic_data/train"

os.listdir(train_out_dir)

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    precision_recall_curve,
    confusion_matrix,
    ConfusionMatrixDisplay,
    roc_curve, roc_auc_score
)
import os

# Nice plotting style
sns.set(style="whitegrid", context="talk")

# Example data (replace with your own)
y_true = np.array([0, 0, 1, 1, 0, 1, 0, 1, 1, 0])
y_scores = np.array([0.05, 0.1, 0.35, 0.8, 0.2, 0.85, 0.4, 0.9, 0.75, 0.3])

# Directory to save plots
save_dir = "/content/drive/MyDrive/archive (3)/trafic_data/train/images"
os.makedirs(save_dir, exist_ok=True)

# Compute metrics
precision, recall, thresholds = precision_recall_curve(y_true, y_scores)
f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)
thresholds_full = np.append(thresholds, 1.0)
best_thresh = thresholds[np.argmax(f1_scores[:-1])]

plt.figure(figsize=(8, 5))
sns.lineplot(x=thresholds_full, y=precision, color='dodgerblue', linewidth=2.5)
plt.axvline(best_thresh, color='red', linestyle='--', label=f'Best Threshold = {best_thresh:.2f}')
plt.xlabel("Decision Threshold")
plt.ylabel("Precision")
plt.title("Precision vs Threshold")
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(save_dir, "P_curve.png"), dpi=300)
plt.show()

plt.figure(figsize=(8, 5))
sns.lineplot(x=thresholds_full, y=recall, color='limegreen', linewidth=2.5)
plt.axvline(best_thresh, color='red', linestyle='--', label=f'Best Threshold = {best_thresh:.2f}')
plt.xlabel("Decision Threshold")
plt.ylabel("Recall")
plt.title("Recall vs Threshold")
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(save_dir, "R_curve.png"), dpi=300)
plt.show()

plt.figure(figsize=(8, 5))
sns.lineplot(x=thresholds_full, y=f1_scores, color='crimson', linewidth=2.5)
plt.axvline(best_thresh, color='black', linestyle='--', label=f'Best Threshold = {best_thresh:.2f}')
plt.scatter(best_thresh, f1_scores[np.argmax(f1_scores[:-1])], color='black', s=80, zorder=3)
plt.xlabel("Decision Threshold")
plt.ylabel("F1 Score")
plt.title("F1 Score vs Threshold")
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(save_dir, "F1_curve.png"), dpi=300)
plt.show()

plt.figure(figsize=(7, 6))
sns.lineplot(x=recall, y=precision, color='mediumpurple', linewidth=2.5)
plt.fill_between(recall, precision, alpha=0.2, color='mediumpurple')
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precisionâ€“Recall Curve")
plt.text(0.05, 0.95, f"Best F1 Threshold: {best_thresh:.2f}", fontsize=12,
         bbox=dict(facecolor='white', alpha=0.8, boxstyle='round'))
plt.tight_layout()
plt.savefig(os.path.join(save_dir, "PR_curve.png"), dpi=300)
plt.show()

y_pred = (y_scores >= best_thresh).astype(int)
cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])
plt.title(f"Confusion Matrix (Threshold = {best_thresh:.2f})")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.tight_layout()
plt.savefig(os.path.join(save_dir, "confusion_matrix.png"), dpi=300)
plt.show()

import pandas as pd

# Read the Excel file (not CSV)
results_df = pd.read_excel("/content/traffic_metrics_cleaned.xlsx")

# Display the first few rows
print(results_df.head())

results_df = pd.read_excel("/content/traffic_metrics_cleaned.xlsx", sheet_name="Sheet1")

columns_list = results_df.columns.tolist()
print(columns_list)

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid", context="talk")

epochs = range(1, len(results_df)+1)  # match the number of rows

plt.figure(figsize=(10, 6))
plt.plot(epochs, results_df["train/box_loss"], color="orange", linewidth=2.5, label="Train Box Loss")
plt.plot(epochs, results_df["val/box_loss"], color="green", linewidth=2.5, label="Validation Box Loss")

plt.xlabel("Epochs")
plt.ylabel("Box Loss")
plt.title("Training vs Validation Box Loss")
plt.legend()
plt.tight_layout()
plt.show()

!pip install ultralytics

!yolo version

!yolo task=detect mode=predict model="/content/drive/MyDrive/archive (3)/trafic_data/train/weights/best.pt" source="/content/drive/MyDrive/archive (3)/trafic_data/valid/images" conf=0.25

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# --- Step 1: Load dataset ---
file_path = "/content/Traffic_Cameras.csv"  # adjust if needed
df = pd.read_csv(file_path)

print("âœ… Dataset loaded successfully!")
print("\nðŸ”¹ First 5 rows:")
print(df.head())
print("\nðŸ“Š Summary:")
print(df.info())
print("\nðŸ§® Missing values per column:")
print(df.isnull().sum())

df.fillna(0, inplace=True)  # Replace NaN with 0
if "status" not in df.columns:
    # create a dummy traffic status column if missing
    df["status"] = df["vehicles"].apply(
        lambda x: "Low" if x <= 5 else ("Moderate" if x <= 15 else "Heavy")
    ) if "vehicles" in df.columns else "Unknown"

if "timestamp" in df.columns:
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors='coerce')
    df["hour"] = df["timestamp"].dt.hour

    plt.figure(figsize=(10, 6))
    sns.lineplot(data=df, x="hour", y="vehicles", marker="o", color="teal")
    plt.title("Average Vehicle Count by Hour")
    plt.xlabel("Hour of Day")
    plt.ylabel("Average Vehicles")
    plt.tight_layout()
    plt.show()

import pandas as pd

df = pd.read_csv("/content/Traffic_Cameras.csv")
print(df.columns)

if "vehicle_count" in df.columns:
    df["status"] = df["vehicle_count"].apply(
        lambda x: "Low" if x <= 5 else ("Moderate" if x <= 15 else "Heavy")
    )
else:
    df["status"] = "Unknown"

df.rename(columns={"traffic_status": "status"}, inplace=True)

df.head()

numeric_df = df.select_dtypes(include=['number'])
plt.figure(figsize=(7, 5))
sns.heatmap(numeric_df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Between Numeric Features")
plt.tight_layout()
plt.show()

print("\nâœ… Analysis Complete!")

# ========================================
# ðŸ” Visualizing Traffic Data with t-SNE
# ========================================

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.manifold import TSNE

# --- Step 1: Load the dataset ---
df = pd.read_csv("/content/Traffic_Cameras.csv")

print("Columns in dataset:\n", df.columns)

# --- Step 2: Handle missing values ---
df.fillna(0, inplace=True)

# --- Step 3: Select numeric features for t-SNE ---
# (You can adjust these depending on what your CSV contains)
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
print("\nNumeric columns being used for t-SNE:\n", numeric_cols)

X = df[numeric_cols]

# --- Step 4: Standardize the features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Step 5: Apply t-SNE for 2D visualization ---
tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)
X_embedded = tsne.fit_transform(X_scaled)

# --- Step 6: Add t-SNE components back to DataFrame ---
df['tsne_1'] = X_embedded[:, 0]
df['tsne_2'] = X_embedded[:, 1]

# --- Step 7: Define colors using your traffic "status" column ---
# If "status" doesn't exist yet, create one based on vehicle count
if "status" not in df.columns:
    if "vehicle_count" in df.columns:
        df["status"] = df["vehicle_count"].apply(
            lambda x: "Low" if x <= 5 else ("Moderate" if x <= 15 else "Heavy")
        )
    else:
        df["status"] = "Unknown"

# --- Step 8: Plot the t-SNE visualization ---
plt.figure(figsize=(10, 7))
sns.scatterplot(
    data=df,
    x='tsne_1', y='tsne_2',
    hue='status',
    palette='coolwarm',
    s=70, alpha=0.8, edgecolor='k'
)
plt.title("t-SNE Visualization of Traffic Patterns", fontsize=15)
plt.xlabel("t-SNE Component 1")
plt.ylabel("t-SNE Component 2")
plt.legend(title="Traffic Status")
plt.tight_layout()
plt.show()

# ==============================================
# ðŸš— Traffic Detection on PNG Image using YOLOv8
# ==============================================

!pip install ultralytics opencv-python-headless --quiet

from ultralytics import YOLO
import cv2
from google.colab.patches import cv2_imshow
import os

# --- Step 1: Load the pretrained YOLOv8 model ---
model = YOLO("yolov8n.pt")  # small pretrained model for general objects
print("âœ… Pretrained YOLOv8 model loaded successfully!")

# --- Step 2: Upload your PNG image or use an existing one ---
# If you're uploading manually:
# from google.colab import files
# uploaded = files.upload()

# Example: using a PNG image already in your path
test_img = "/content/drive/MyDrive/archive (3)/trafic_data/train/images/05_jpg.rf.11a2e7ce391a1e74960099f7923f27f5.jpg"  # ðŸ‘ˆ Change this to your actual PNG file path

if not os.path.exists(test_img):
    print("âš ï¸ Image not found! Please check the path or upload your image.")
else:
    print(f"âœ… Found image: {test_img}")

# --- Step 3: Run YOLO detection on the image ---
results = model.predict(source=test_img, conf=0.4)  # conf = confidence threshold

# --- Step 4: Visualize the results ---
annotated_img = results[0].plot()
cv2_imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))

# --- Step 5: Optional â€” Save annotated image ---
save_path = "/content/drive/MyDrive/archive (3)/trafic_data/train/images/05_jpg.rf.11a2e7ce391a1e74960099f7923f27f5.jpg"
cv2.imwrite(save_path, cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))
print(f"ðŸ’¾ Saved annotated image as: {save_path}")

# ===============================================
# ðŸš— Advanced Traffic Detection using YOLOv8x
# ===============================================

!pip install ultralytics opencv-python-headless --quiet

from ultralytics import YOLO
import cv2
from google.colab.patches import cv2_imshow
import os

# --- Step 1: Load the high-accuracy YOLOv8x model ---
model = YOLO("yolov8x.pt")  # Larger model â†’ higher accuracy
print("âœ… Advanced YOLOv8x model loaded successfully!")

# --- Step 2: Use your PNG or JPG image ---
# Example path (update this to your image)
test_img = "/content/drive/MyDrive/archive (3)/trafic_data/train/images/100_jpg.rf.971dbb99e07828d1655d69bbfb7136be.jpg"

if not os.path.exists(test_img):
    print("âš ï¸ Image not found! Upload your image using:")
    print("from google.colab import files; files.upload()")
else:
    print(f"âœ… Found image: {test_img}")

# --- Step 3: Run YOLO inference with higher resolution ---
results = model.predict(
    source=test_img,
    conf=0.45,      # confidence threshold
    imgsz=1280,     # larger image size â†’ better accuracy
    iou=0.5,        # intersection-over-union threshold
    show=False
)

# --- Step 4: Count vehicles and classify traffic level ---
vehicle_classes = ["car", "bus", "truck", "motorbike", "bicycle"]
cls_counts = {}

for box in results[0].boxes:
    cls_id = int(box.cls)
    cls_name = results[0].names[cls_id]
    if cls_name in vehicle_classes:
        cls_counts[cls_name] = cls_counts.get(cls_name, 0) + 1

total_vehicles = sum(cls_counts.values())

# Traffic level logic
if total_vehicles <= 5:
    traffic_status = "Low Traffic ðŸš¦"
elif total_vehicles <= 15:
    traffic_status = "Moderate Traffic ðŸš§"
else:
    traffic_status = "Heavy Traffic ðŸš—ðŸ’¨"

print("\nðŸ“Š Vehicle Counts:")
for name, count in cls_counts.items():
    print(f" - {name}: {count}")
print(f"ðŸ”¸ Total Vehicles: {total_vehicles}")
print(f"ðŸš¦ Traffic Status: {traffic_status}")

# --- Step 5: Visualize detection result ---
annotated_img = results[0].plot()

# Add text overlay with traffic status
cv2.putText(annotated_img, traffic_status, (30, 60),
            cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3, cv2.LINE_AA)

cv2_imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))

# --- Step 6: Optional â€” Save the annotated output ---
save_path = "/content/drive/MyDrive/archive (3)/trafic_data/train/images/100_jpg.rf.971dbb99e07828d1655d69bbfb7136be.jpg"
cv2.imwrite(save_path, cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))
print(f"ðŸ’¾ Saved annotated image at: {save_path}")

# ===============================================
# ðŸš— Advanced Multi-Image Traffic Detection (10 JPGs)
# ===============================================

!pip install ultralytics opencv-python-headless pandas --quiet

from ultralytics import YOLO
import cv2
from google.colab.patches import cv2_imshow
import os
import pandas as pd

# --- Step 1: Load advanced YOLO model ---
model = YOLO("yolov8x.pt")  # More accurate but slightly slower
print("âœ… YOLOv8x model loaded successfully!")

# --- Step 2: Set your images folder ---
image_folder = "/content/drive/MyDrive/archive (3)/trafic_data/train/images"

# Pick up to 10 JPG images
image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(".jpg")][:10]
print(f"ðŸ–¼ Found {len(image_files)} images for detection.")

# --- Step 3: Prepare output folder ---
output_folder = "/content/traffic_results"
os.makedirs(output_folder, exist_ok=True)

# --- Step 4: Define vehicle classes ---
vehicle_classes = ["car", "bus", "truck", "motorbike", "bicycle"]

# --- Step 5: Run detection on each image ---
results_data = []

for img_path in image_files:
    print(f"\nðŸ” Processing: {os.path.basename(img_path)}")
    results = model.predict(source=img_path, conf=0.45, imgsz=1280, iou=0.5, show=False)

    boxes = results[0].boxes
    cls_counts = {}
    for box in boxes:
        cls_id = int(box.cls)
        cls_name = results[0].names[cls_id]
        if cls_name in vehicle_classes:
            cls_counts[cls_name] = cls_counts.get(cls_name, 0) + 1

    total_vehicles = sum(cls_counts.values())

    # --- Traffic Status Logic ---
    if total_vehicles <= 5:
        status = "Low Traffic ðŸš¦"
    elif total_vehicles <= 15:
        status = "Moderate Traffic ðŸš§"
    else:
        status = "Heavy Traffic ðŸš—ðŸ’¨"

    # --- Annotate image ---
    annotated_img = results[0].plot()
    cv2.putText(annotated_img, status, (30, 60),
                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3, cv2.LINE_AA)

    # --- Save annotated output ---
    save_path = os.path.join(output_folder, f"result_{os.path.basename(img_path)}")
    cv2.imwrite(save_path, cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))

    # --- Show one sample image (optional) ---
    cv2_imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))

    # --- Store results ---
    results_data.append({
        "Image": os.path.basename(img_path),
        "Total Vehicles": total_vehicles,
        "Traffic Status": status,
        **cls_counts
    })

# --- Step 6: Save results to CSV ---
results_df = pd.DataFrame(results_data)
csv_path = os.path.join(output_folder, "traffic_analysis_results.csv")
results_df.to_csv(csv_path, index=False)

print("\nâœ… Detection complete for all images!")
print(f"ðŸ’¾ Results saved at: {csv_path}")

# Display summary table
print("\nðŸ“Š Summary of Traffic Detection:")
display(results_df)

# ==================================================
# ðŸš— High Traffic Detection on One Image (YOLOv8x)
# ==================================================

!pip install ultralytics opencv-python-headless --quiet

from ultralytics import YOLO
import cv2
from google.colab.patches import cv2_imshow
import os

# --- Step 1: Load YOLOv8x Model ---
model = YOLO("yolov8x.pt")  # High-accuracy model
print("âœ… YOLOv8x model loaded successfully!")

# --- Step 2: Specify your image ---
# Example: replace this path with your actual image (.jpg or .png)
image_path = "/content/drive/MyDrive/archive (3)/trafic_data/train/images/64_jpg.rf.e88dfd8566cbc446c44650ea0b13d8d3.jpg"

if not os.path.exists(image_path):
    raise FileNotFoundError("âš ï¸ Image not found! Please check your image path.")

# --- Step 3: Run detection ---
results = model.predict(source=image_path, conf=0.4, imgsz=1280, iou=0.5)
boxes = results[0].boxes
classes = results[0].names

# --- Step 4: Count vehicle types ---
vehicle_classes = ["car", "bus", "truck", "motorbike", "bicycle"]
cls_counts = {}

for box in boxes:
    cls_id = int(box.cls)
    cls_name = classes[cls_id]
    if cls_name in vehicle_classes:
        cls_counts[cls_name] = cls_counts.get(cls_name, 0) + 1

total_vehicles = sum(cls_counts.values())

# --- Step 5: Determine traffic condition ---
if total_vehicles <= 5:
    status = "Low Traffic ðŸš¦"
    color = (0, 255, 0)
elif total_vehicles <= 15:
    status = "Moderate Traffic ðŸš§"
    color = (0, 255, 255)
else:
    status = "High Traffic ðŸš—ðŸ’¨"
    color = (0, 0, 255)

print(f"\nðŸš˜ Vehicle Counts: {cls_counts}")
print(f"ðŸ”¹ Total Vehicles: {total_vehicles}")
print(f"ðŸš¦ Traffic Status: {status}")

# --- Step 6: Display annotated image ---
annotated_img = results[0].plot()

# Add status text on image
cv2.putText(annotated_img, status, (30, 60),
            cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3, cv2.LINE_AA)

cv2_imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))

# --- Step 7: Save result ---
save_path = "/content/drive/MyDrive/archive (3)/trafic_data/train/images/64_jpg.rf.e88dfd8566cbc446c44650ea0b13d8d3.jpg"
cv2.imwrite(save_path, cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))
print(f"ðŸ’¾ Result saved at: {save_path}")

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import kagglehub

# Download latest version
path = kagglehub.dataset_download("khushikyad001/indian-traffic-violation")

print("Path to dataset files:", path)

import kagglehub
import pandas as pd
import os

# Step 1: Download the dataset
dataset_path = kagglehub.dataset_download("khushikyad001/indian-traffic-violation")
print("Dataset downloaded to:", dataset_path)

# Step 2: Locate the CSV file
# Assuming there's only one CSV file in the dataset folder
csv_files = [f for f in os.listdir(dataset_path) if f.endswith(".csv")]
if not csv_files:
    raise FileNotFoundError("No CSV file found in the dataset directory.")

csv_path = os.path.join(dataset_path, csv_files[0])
print("Using CSV file:", csv_path)

# Step 3: Load the dataset
df = pd.read_csv(csv_path)

# Step 4: Display all column names
print("Columns in the dataset:")
print(df.columns.tolist())

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv("/kaggle/input/indian-traffic-violation/Indian_Traffic_Violations.csv")

# Group by violation type and sum fines
violation_fines = df.groupby("Violation_Type")["Fine_Amount"].sum().sort_values(ascending=False)

# Plotting
plt.figure(figsize=(12, 6))
sns.barplot(x=violation_fines.values, y=violation_fines.index, palette="viridis")
plt.title("Total Fines by Violation Type", fontsize=16)
plt.xlabel("Total Fine Amount (â‚¹)", fontsize=12)
plt.ylabel("Violation Type", fontsize=12)
plt.tight_layout()
plt.show()

pivot_table = df.pivot_table(
    index='Violation_Type',
    columns='Vehicle_Type',
    values='Fine_Amount',
    aggfunc='mean'
)

# Create the heatmap
plt.figure(figsize=(14, 8))
sns.heatmap(pivot_table, annot=True, fmt=".0f", cmap='YlOrRd', linewidths=.5, linecolor='gray')
plt.title("Average Fine Amounts by Violation Type and Vehicle Type", fontsize=16)
plt.xlabel("Vehicle Type")
plt.ylabel("Violation Type")
plt.tight_layout()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# For notebook inline plotting (remove if running as script)
# %matplotlib inline
sns.set(style="whitegrid")

# Load dataset
df = pd.read_csv("/kaggle/input/indian-traffic-violation/Indian_Traffic_Violations.csv")

# Clean and preprocess
df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
df = df[df['Fine_Amount'].notna()]
df = df[df['Date'].dt.year.between(2023, 2025)]

# Bin fines into ranges
upper_limit = max(15000, df['Fine_Amount'].max())
bins = [0, 500, 1000, 2000, 5000, 10000, upper_limit]
labels = ['< â‚¹500', 'â‚¹500â€“â‚¹999', 'â‚¹1000â€“â‚¹1999', 'â‚¹2000â€“â‚¹4999', 'â‚¹5000â€“â‚¹9999', 'â‚¹10,000+']
df['Fine_Range'] = pd.cut(df['Fine_Amount'], bins=bins, labels=labels, include_lowest=True)

# Extract Month in "YYYY-MM" format
df['Month'] = df['Date'].dt.to_period('M').astype(str)

# List all unique violation types
violation_types = df['Violation_Type'].unique()

# Ensure there are exactly 9 unique violation types
assert len(violation_types) == 9, f"Expected 9 violation types, found {len(violation_types)}."

# Loop through all violation types
for violation in violation_types:
    subset = df[df['Violation_Type'] == violation]

    # Group by Violation Type, Registration State, and Fine Range
    grouped = subset.groupby(['Registration_State', 'Fine_Range']).size().unstack(fill_value=0)

    # Plot stacked bar chart
    plt.figure(figsize=(14, 8))
    grouped.plot(kind='bar', stacked=True, color=sns.color_palette("Set3", len(labels)), width=0.8)

    # Customize the plot
    plt.title(f"Violation Type: {violation} - Fine Distribution by State and Fine Range", fontsize=16)
    plt.xlabel("Registration State", fontsize=12)
    plt.ylabel("Number of Fines", fontsize=12)
    plt.xticks(rotation=45, ha="right")
    plt.legend(title="Fine Range", labels=labels, bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()

    # Show the plot
    plt.show()

